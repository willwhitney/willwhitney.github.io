---
layout: page
title: About Me
---

![me in lab](assets/img/in_lab.jpg)

I'm Will Whitney, a research scientist at DeepMind on the Control team. I got my PhD working with Kyunghyun Cho at NYU. Before that I worked with Josh Tenenbaum and Tejas Kulkarni at MIT for my Master's. In a past life I started a company and went through Y Combinator. I also created [Hydrogen](https://atom.io/packages/hydrogen), an interactive coding environment for the Atom text editor, which was downloaded >2,000,000 times.

## Research interests
My research focuses on the problem of sample-efficient learning, mostly in the domain of robotics. What kinds of algorithms can take advantage of the structure of our 3D physical world to make learning more efficient, and how do they scale with additional data?


## Publications

This page is typically outdated, so refer to my [Semantic Scholar](https://www.semanticscholar.org/author/William-F.-Whitney/3376546) instead.

William F. Whitney, Michael Bloesch, Jost Tobias Springenberg, Abbas Abdolmaleki, and Martin Riedmiller. [Rethinking Exploration for Sample-Efficient Policy Learning](assets/papers/Rethinking.Exploration.for.Sample.Efficient.Policy.Learning.pdf). Working paper. _arXiv preprint arXiv:2101.09458_, 2021.

David Brandfonbrener, William F. Whitney, Rajesh Ranganath, and Joan Bruna. [Offline Contextual Bandits with Overparameterized Models](assets/papers/Offline.Contextual.Bandits.with.Overparameterized.Models.pdf). In submission, 2021.

William F. Whitney, Min Jae Song, David Brandfonbrener, Jaan Altosaar, and Kyunghyun Cho. [Evaluating representations by the complexity of learning low-loss predictors](assets/papers/Evaluating.representations.by.the.complexity.of.learning.low.loss.predictors.pdf). In submission, 2021.

William F. Whitney, Rajat Agarwal, Kyunghyun Cho, and Abhinav Gupta. [Dynamics-aware Embeddings](assets/papers/Dynamics.aware.Embeddings.pdf). In _International Conference on Learning Representations_, 2020.

William F. Whitney and Abhinav Gupta. [Learning Effect-Dependent Embeddings for Temporal Abstraction](http://willwhitney.com/assets/papers/Learning.Effect.Dependent.Embeddings.pdf). In _Structure & Priors in Reinforcement Learning_ at ICLR 2019.

William F. Whitney and Rob Fergus. [Understanding the Asymptotic Performance of Model-Based RL Methods](assets/papers/Understanding.the.Asymptotic.Performance.of.MBRL.pdf). 2018.

William F. Whitney and Rob Fergus. [Disentangling video with independent prediction](assets/papers/Disentangling.video.with.independent.prediction.pdf). In _Learning Disentangled Representations: from Perception to Control_ at NeurIPS'17. 2017.

Mikael Henaff, William F. Whitney, and Yann LeCun. [Model-Based Planning with Discrete and Continuous Actions](assets/papers/Model.Based.Planning.with.Discrete.and.Continuous.Actions.pdf). _arXiv preprint arXiv:1705.07177_, 2017.

Vlad Firoiu, William F. Whitney, and Joshua B. Tenenbaum. [Beating the worldâ€™s best at Super Smash Bros. with deep reinforcement learning](assets/papers/Beating.the.Worlds.Best.pdf). _arXiv preprint arXiv:1702.06230_, 2017.

William F. Whitney. [Disentangled Representations in Neural Models](assets/papers/Disentangled.Representations.in.Neural.Models.pdf). Master's thesis, Massachusetts Institute of Technology, 2016.

William F. Whitney, Michael Chang, Tejas Kulkarni, and Joshua B. Tenenbaum. [Understanding visual concepts with continuation learning](assets/papers/Understanding.Visual.Concepts.with.Continuation.Learning.pdf). In _International Conference on Learning Representations, Workshop Track_, 2016.

Tejas D. Kulkarni[^1], William F. Whitney[^1], Pushmeet Kohli, and Joshua B. Tenenbaum. [Deep convolutional inverse graphics network](assets/papers/Deep.Convolutional.Inverse.Graphics.Network.pdf). In _Advances in Neural Information Processing Systems_, 2015.
Spotlight presentation given by William Whitney.

[^1]: Equal contribution.
