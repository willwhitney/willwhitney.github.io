---
layout: page
title: About Me
---

![me in lab](assets/img/in_lab.jpg)

I'm Will Whitney, a PhD student working with Kyunghyun Cho at NYU. I've done internships at DeepMind with Martin Riedmiller and at FAIR with Abhinav Gupta. Before this I worked with Josh Tenenbaum and Tejas Kulkarni at MIT for my Master's. In a past life I started a company and went through Y Combinator. I'm also the creator of [Hydrogen](https://atom.io/packages/hydrogen), an interactive coding environment for the Atom text editor, which has been downloaded >2,000,000 times.

## Research interests
My research focuses on the problem of sample-efficient learning, mostly in the domain of reinforcement learning for continuous control. This breaks down into a few smaller problems:

- How should we explore in order to learn a policy as rapidly as possible with off-policy RL?
- What factors make an algorithm work well or poorly when trained with data that is very far off policy?
- What auxiliary objectives or artifacts, such as learned representations, would enable learning to be more sample efficient?

Previously I worked on generative models with interpretable latent spaces. My interests include the inductive biases of neural networks, learned structure in latent spaces, and robotics. I've also been interested in questions of sample complexity and expressivity: what makes a function easy or hard to approximate with a neural network?


## Publications

William F. Whitney, Michael Bloesch, Jost Tobias Springenberg, Abbas Abdolmaleki, and Martin Riedmiller. [Rethinking Exploration for Sample-Efficient Policy Learning](assets/papers/Rethinking.Exploration.for.Sample.Efficient.Policy.Learning.pdf). Working paper. _arXiv preprint arXiv:2101.09458_, 2021.

David Brandfonbrener, William F. Whitney, Rajesh Ranganath, and Joan Bruna. [Bandit Overfitting in Offline Policy Learning](assets/papers/Bandit.Overfitting.in.Offline.Policy.Learning.pdf). In submission, 2021.

William F. Whitney, Min Jae Song, David Brandfonbrener, Jaan Altosaar, and Kyunghyun Cho. [Evaluating representations by the complexity of learning low-loss predictors](assets/papers/Evaluating.representations.by.the.complexity.of.learning.low.loss.predictors.pdf). In submission, 2021.

William F. Whitney, Rajat Agarwal, Kyunghyun Cho, and Abhinav Gupta. [Dynamics-aware Embeddings](assets/papers/Dynamics.aware.Embeddings.pdf). In _International Conference on Learning Representations_, 2020.

William F. Whitney and Abhinav Gupta. [Learning Effect-Dependent Embeddings for Temporal Abstraction](http://willwhitney.com/assets/papers/Learning.Effect.Dependent.Embeddings.pdf). In _Structure & Priors in Reinforcement Learning_ at ICLR 2019.

William F. Whitney and Rob Fergus. [Understanding the Asymptotic Performance of Model-Based RL Methods](assets/papers/Understanding.the.Asymptotic.Performance.of.MBRL.pdf). 2018.

William F. Whitney and Rob Fergus. [Disentangling video with independent prediction](assets/papers/Disentangling.video.with.independent.prediction.pdf). In _Learning Disentangled Representations: from Perception to Control_ at NeurIPS'17. 2017.

Mikael Henaff, William F. Whitney, and Yann LeCun. [Model-Based Planning with Discrete and Continuous Actions](assets/papers/Model.Based.Planning.with.Discrete.and.Continuous.Actions.pdf). _arXiv preprint arXiv:1705.07177_, 2017.

Vlad Firoiu, William F. Whitney, and Joshua B. Tenenbaum. [Beating the worldâ€™s best at Super Smash Bros. with deep reinforcement learning](assets/papers/Beating.the.Worlds.Best.pdf). _arXiv preprint arXiv:1702.06230_, 2017.

William F. Whitney. [Disentangled Representations in Neural Models](assets/papers/Disentangled.Representations.in.Neural.Models.pdf). Master's thesis, Massachusetts Institute of Technology, 2016.

William F. Whitney, Michael Chang, Tejas Kulkarni, and Joshua B. Tenenbaum. [Understanding visual concepts with continuation learning](assets/papers/Understanding.Visual.Concepts.with.Continuation.Learning.pdf). In _International Conference on Learning Representations, Workshop Track_, 2016.

Tejas D. Kulkarni[^1], William F. Whitney[^1], Pushmeet Kohli, and Joshua B. Tenenbaum. [Deep convolutional inverse graphics network](assets/papers/Deep.Convolutional.Inverse.Graphics.Network.pdf). In _Advances in Neural Information Processing Systems_, 2015.
Spotlight presentation given by William Whitney.

[^1]: Equal contribution.
